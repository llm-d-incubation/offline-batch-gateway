version: '3.8'

services:
  llm-d-mock-server:
    image: ghcr.io/llm-d/llm-d-inference-sim:latest
    container_name: llm-d-mock-server-test
    ports:
      - "8100:8000"
    command:
      - --port=8000
      - --model=fake-model
      - --mode=random
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 2s
      timeout: 1s
      retries: 10
      start_period: 2s
