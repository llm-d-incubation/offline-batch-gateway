# Database Connection
database_url: ""

# Worker Settings - task wait time needs to be shorter than poll interval
task_wait_time: "1s"
worker_poll_interval: "5s"
max_workers: 20
queue_time_bucket:
  bucket_start: 0.1
  bucket_factor: 2
  bucket_count: 10
process_time_bucket:
  bucket_start: 0.1
  bucket_factor: 2
  bucket_count: 15

# Metrics & Health Check
metrics_address: ":9090"

# Inference Client Configuration
# Base URL of the inference gateway (llm-d or other OpenAI-compatible endpoint)
inference_gateway_url: "http://localhost:8000"

# Request timeout for individual inference requests
inference_request_timeout: "5m"

# Optional API key for authenticating with the inference gateway
# Leave empty if no authentication is required
inference_api_key: ""

# Retry configuration for failed requests
inference_max_retries: 3
inference_initial_backoff: "1s"
inference_max_backoff: "60s"

# TLS configuration (optional)
# Skip TLS certificate verification (INSECURE - only for testing with self-signed certs)
inference_tls_insecure_skip_verify: false

# Custom CA certificate for private/corporate CAs
# inference_tls_ca_cert_file: "/path/to/ca-cert.pem"

# Client certificate and key for mutual TLS (mTLS)
# inference_tls_client_cert_file: "/path/to/client-cert.pem"
# inference_tls_client_key_file: "/path/to/client-key.pem"